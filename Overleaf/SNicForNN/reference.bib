@article{siracusano2020running,
  title={Running Neural Networks on the NIC},
  author={Siracusano, Giuseppe and Galea, Salvator and Sanvito, Davide and Malekzadeh, Mohammad and Haddadi, Hamed and Antichi, Gianni and Bifulco, Roberto},
  journal={arXiv preprint arXiv:2009.02353},
  year={2020}
}
@manual{netfpga-sume,
  author = "Xilinx",
  title  = "NetFPGA-SUME Virtex-7 FPGA Development Board",
  note   = "\url{https://www.xilinx.com/products/boards-and-kits/1-6ogkf5.html}",
  year   = "2021 (accessed April 15, 2021)"
}
@manual{liquidio,
  author = "Cavium",
  title  = "LiquidIO-II 10/25G Smart NIC Family",
  note   = "\url{https://www.marvell.com/content/dam/marvell/en/public-collateral/ethernet-adaptersandcontrollers/marvell-ethernet-liquidio-ii-cn23xx-10g-25g-product-brief-2017.pdf}",
  year   = "2021 (accessed April 15, 2021)"
}
@manual{stingray,
  author = "Broadcom",
  title  = "Stingray PS225",
  note   = "\url{https://docs.broadcom.com/doc/PS225-PB}",
  year   = "2021 (accessed April 15, 2021)"
}
@manual{tflite,
  title  = "TensorFlow Lite | ML for Mobile and Edge Devices",
  note   = "\url{https://www.tensorflow.org/lite}",
  year   = "2021 (accessed April 15, 2021)"
}

@manual{bluefield,
  author = "Mellanox",
  title  = "BlueField SmartNIC for Ethernet High Performance Ethernet Network Adapter Cards",
  note   = "\url{https://www.mellanox.com/sites/default/files/related-docs/prod_adapter_cards/PB_BlueField_Smart_NIC.pdf}",
  year   = "2021 (accessed April 15, 2021)"
}

@inproceedings{10.1145/3341302.3342079,
author = {Liu, Ming and Cui, Tianyi and Schuh, Henry and Krishnamurthy, Arvind and Peter, Simon and Gupta, Karan},
title = {Offloading Distributed Applications onto SmartNICs Using IPipe},
year = {2019},
isbn = {9781450359566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3341302.3342079},
doi = {10.1145/3341302.3342079},
pages = {318â€“333},
numpages = {16},
keywords = {SmartNIC, distributed applications},
location = {Beijing, China},
series = {SIGCOMM '19}
}
@inproceedings {211249,
author = {Daniel Firestone and Andrew Putnam and Sambhrama Mundkur and Derek Chiou and Alireza Dabagh and Mike Andrewartha and Hari Angepat and Vivek Bhanu and Adrian Caulfield and Eric Chung and Harish Kumar Chandrappa and Somesh Chaturmohta and Matt Humphrey and Jack Lavier and Norman Lam and Fengfen Liu and Kalin Ovtcharov and Jitu Padhye and Gautham Popuri and Shachar Raindel and Tejas Sapre and Mark Shaw and Gabriel Silva and Madhan Sivakumar and Nisheeth Srivastava and Anshuman Verma and Qasim Zuhair and Deepak Bansal and Doug Burger and Kushagra Vaid and David A. Maltz and Albert Greenberg},
title = {Azure Accelerated Networking: SmartNICs in the Public Cloud},
booktitle = {15th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 18)},
year = {2018},
isbn = {978-1-939133-01-4},
address = {Renton, WA},
pages = {51--66},
url = {https://www.usenix.org/conference/nsdi18/presentation/firestone},
publisher = {{USENIX} Association},
month = apr,
}

@inproceedings {234944,
author = {Ming Liu and Simon Peter and Arvind Krishnamurthy and Phitchaya Mangpo Phothilimthana},
title = {E3: Energy-Efficient Microservices on SmartNIC-Accelerated Servers},
booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
year = {2019},
isbn = {978-1-939133-03-8},
address = {Renton, WA},
pages = {363--378},
url = {https://www.usenix.org/conference/atc19/presentation/liu-ming},
publisher = {{USENIX} Association},
month = jul,
}

@INPROCEEDINGS{8999396,
  author={Geyer, Fabien and Schmid, Stefan},
  booktitle={2019 IFIP Networking Conference (IFIP Networking)}, 
  title={DeepMPLS: fast analysis of MPLS configurations using deep learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-9},
  doi={10.23919/IFIPNetworking46909.2019.8999396},
  organization={IEEE}}
  
@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}
@inproceedings{10.1145/3372224.3419215,
author = {Huang, Jin and Samplawski, Colin and Ganesan, Deepak and Marlin, Benjamin and Kwon, Heesung},
title = {CLIO: Enabling Automatic Compilation of Deep Learning Pipelines across IoT and Cloud},
year = {2020},
isbn = {9781450370851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372224.3419215},
doi = {10.1145/3372224.3419215},
abstract = {Recent years have seen dramatic advances in low-power neural accelerators that aim to bring deep learning analytics to IoT devices; simultaneously, there have been considerable advances in the design of low-power radios to enable efficient compute offload from IoT devices to the cloud. Neither is a panacea --- deep learning models are often too large for low-power accelerators and bandwidth needs are often too high for low-power radios. While there has been considerable work on deep learning for smartphone-class devices, these methods do not work well for small battery-powered IoT devices that are considerably more resource-constrained.In this paper, we bridge this gap by designing a continuously tunable method for leveraging both local and remote resources to optimize performance of a deep learning model. Clio presents a novel approach to split machine learning models between an IoT device and cloud in a progressive manner that adapts to wireless dynamics. We show that this method can be combined with model compression and adaptive model partitioning to create an integrated system for IoT-cloud partitioning. We implement Clio on the GAP8 low-power neural accelerator, provide an exhaustive characterization of the operating regimes where each method performs best and show that Clio can enable graceful performance degradation as resources diminish.},
booktitle = {Proceedings of the 26th Annual International Conference on Mobile Computing and Networking},
articleno = {58},
numpages = {12},
keywords = {edge computing, computation off-loading, deep neural networks, cloud computing},
location = {London, United Kingdom},
series = {MobiCom '20}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{abadi2016tensorflow, 
  title={Tensorflow: A system for large-scale machine learning}, 
  author={Abadi, Mart{\'\i}n and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and others}, 
  booktitle={12th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 16)}, 
  pages={265--283}, 
  year={2016} 
}

@misc{petimages,
  author = {Microsoft},
  title = {Cats and Dogs Dataset},
  howpublished = {\url{https://www.kaggle.com/karakaggle/kaggle-cat-vs-dog-dataset}},
  note = {Accessed: April 15, 2021}
}

@inproceedings{UNSW,
author = {Moustafa, Nour and Slay, Jill},
year = {2015},
month = {11},
pages = {},
title = {UNSW-NB15: a comprehensive data set for network intrusion detection systems (UNSW-NB15 network data set)},
doi = {10.1109/MilCIS.2015.7348942}
}

@software{sdn2021git,
   author = {Hesam Tajbakhsh},
   title={SDN2021-InNetworkNN},
   url = {https://github.com/hesam4g/SDN2021-InNetworkNN.git},
   date = {2021},
 }
 
 @InProceedings{10.1007/978-3-319-17248-4_7,
author="Lo, Yu Jung
and Williams, Samuel
and Van Straalen, Brian
and Ligocki, Terry J.
and Cordery, Matthew J.
and Wright, Nicholas J.
and Hall, Mary W.
and Oliker, Leonid",
editor="Jarvis, Stephen A.
and Wright, Steven A.
and Hammond, Simon D.",
title="Roofline Model Toolkit: A Practical Tool for Architectural and Program Analysis ",
booktitle="High Performance Computing Systems. Performance Modeling, Benchmarking, and Simulation",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="129--148",
abstract="We present preliminary results of the Roofline Toolkit for multicore, manycore, and accelerated architectures. This paper focuses on the processor architecture characterization engine, a collection of portable instrumented micro benchmarks implemented with Message Passing Interface (MPI), and OpenMP used to express thread-level parallelism. These benchmarks are specialized to quantify the behavior of different architectural features. Compared to previous work on performance characterization, these microbenchmarks focus on capturing the performance of each level of the memory hierarchy, along with thread-level parallelism, instruction-level parallelism and explicit SIMD parallelism, measured in the context of the compilers and run-time environments. We also measure sustained PCIe throughput with four GPU memory managed mechanisms. By combining results from the architecture characterization with the Roofline model based solely on architectural specifications, this work offers insights for performance prediction of current and future architectures and their software systems. To that end, we instrument three applications and plot their resultant performance on the corresponding Roofline model when run on a Blue Gene/Q architecture.",
isbn="978-3-319-17248-4"
}
