\section{Results}
\label{sec-results}

In this section, we report the results gained in the given testbed. First, we lecture about VGG16's results. Then, we report roofline results to clarify the results we provided. At the end of this section, we express the MLP classifier's results.

\subsection{VGG16's Results}
Our evaluation after training depicts the original model and the lite version have 90.6\% and 90.1\% accuracy, respectively. Besides, Table \ref{vgg16} shows the latencies for VGG16 applications. First, we measured the overall latencies for both the \smartnic and the host. The host is 5x faster to calculate the response with the VGG16 model due to results compared to the \smartnic. Considering this, we break down the overall latency to find out which time slot needs more time.  As we can understand from the fourth column of Table \ref{vgg16}, performing the model operations takes 5x times inside \smartnic's CPU. For better understanding, we perform Roofline benchmark to figure out if the results make sense. The results are reported in Table \ref{roofline-results}. The results in the given table show that the host is 8x-10x quicker than the \smartnic. Since VGG16 is a very deep neural network demanding many complex operations, and the \smartnic has limited resources, the overall latency and computation time for the \smartnic are reasonable.

\begin{table*}[hbt!]
\caption{VGG16's Results}
\label{vgg16}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Device                         & Framework       & Total Latency & Computation Time & Loading the Image & Communication Time \\ \hline
\smartnic (ARM) & TensorFlow lite & 493.58 ms     & 470.99 ms        & 16.88 ms          & 5.71 ms            \\ \hline
Host (x86)                     & TensorFlow      & 107.05 ms     & 97.98 ms         & 5.21 ms           & 3.86 ms            \\ \hline
\end{tabular}
\end{table*}


\begin{table*}[hbt!]
\caption{Roofline's Results}
\label{roofline-results}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Device                                   & CPU Bound    & Max L1 Speed & Max L2 Speed & Max L3 Speed & Max DRAM Speed \\ \hline
\smartnic (Arm), One Core & 1.1 GFLOP/s  & 14.5 GB/s    & 4.7 GB/s     & 3.2 GB/s     & 2.4 GB/s       \\ \hline
\smartnic (ARM), 16 Cores & 17.6 GFLOP/s & 231 GB/s     & 19.9 GB/s    & 14.1 GB/s    & 10.6 GB/s      \\ \hline
Host (x86), One Core                    & 9.1 GFLOP/s  & 101.0 GB/s   & 73.2 GB/s    & 36.3 GB/s    & 19.7 GB/s      \\ \hline
Host (x86), 16 Cores                     & 91 GFLOP/s   & 1009.4 GB/s  & 49.9 GB/s    & 35.2 GB/s    & 26.8 GB/s      \\ \hline
\end{tabular}
\end{table*}


\subsection{MLP Classifier's Results}
In these experiments, we load exactly the same model either on the \smartnic or on the host for anomaly detection. Consequently, in both cases, the accuracy is the same, nearby 96.03\%. Since the load for this experiment is not much, we run the server code on one core. In addition to that, we increased the number of connections on the client-side. The measured results are expressed in Table \ref{mlp-results} illustrating how long it takes for the server to respond. Excluding eight connections, both the \smartnic and the host have more or less the same latencies. Averages are less for the \smartnic than the host, while the standard deviation is higher than the host. Once we set the number of connections to eight, the \smartnic works fine, with reasonable changes in the results. However, the host's CPU utilization reaches 100\%; consequently, the connections are refused, and the numbers would not be acceptable anymore.
\par
Further, the communication times demonstrate that the \smartnic would be a good fit for the applications demanding high communication, such as I/O intensive loads. In other words, the \smartnic has faster access to the PCI Express slot than the host; keeping in mind that several devices can be mounted on the host through the slot, and x86 should handle the challenge as well.
\par
Evaluating these applications is beyond our project. Eventually, owing to these results, we can understand, MLP classifiers are a good fit for executing on the \smartnic; one wimpy core of the \smartnic can have the same performance compared to one powerful core of the host.

\begin{table*}[hbt!]
\caption{Average Latencies for the MLP classifier to Detect the Anomaly.}
\label{mlp-results}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{Average (Standard Deviation) of the Latancies in ms}                   \\ \hline
Device:       & \multicolumn{2}{c|}{\smartnic (ARM)} & \multicolumn{2}{c|}{Host (x86)}      \\ \hline
The Number of Connections & Overall Latency & Communication Time & Overall Latency & Communication Time \\ \hline
1             & 3.89 (2.99)     & 1.14 (0.18)        & 4.01 (1.01)     & 1.67 (0.19)        \\ \hline
2             & 4.00 (7.98)     & 0.62 (0.42)        & 4.02 (1.46)     & 1.69 (0.9)         \\ \hline
4             & 4.2 (19.41)     & 0.2 (0.12)         & 4.6 (3.13)      & 1.10 (1.49)        \\ \hline
8             & 12.56 (31.04)   & 0.47 (4.44)        & N/A             & N/A                \\ \hline
\end{tabular}
\end{table*}