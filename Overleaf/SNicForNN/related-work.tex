\section{Related work}
\label{sec-related}

\textcolor{red}{Offloading other applications to SmartNICs.}

Many researchers studied different aspects of \smartnics, and how \smartnics can be used wisely to provide better performance even with comparison hosts with powerful CPUs. Long story short, we picked a few of them here.
\par
Ming \etal in \cite{10.1145/3341302.3342079} extended three well-known distributed applications to use the proposed framework's APIs (called iPipe) and benefit \smartnics interests, such as saving up the Host's CPU and more agile latency. The applications explored are a replicated key-value store, a distributed transaction system, and a real-time analytics engine. Furthermore, two on-path and two off-path \smartnics using embedded CPU have been investigated. Characterizing the performance of each \smartnics, they acquainted iPipe framework for distributed applications. The framework providing actor-based programming consists of three major components, an actor scheduler, a distributed memory object abstraction for actor migration, and, eventually, a security isolation mechanism. Carried out experiments manifest that on-path \smartnics show better performance than off-path ones.
\par
Daniel \etal \cite{211249} conferred a solution to offload networking in a virtualized environment into \smartnics and accepted the FPGA-based one as the best decision for both speed and programmability. Single Root I/O Virtualization is introduced in a nutshell, allowing VMs to have direct access to \smartnics. Moreover, the NIC is responsible for all network management. Their given method provided the quickest latency for a public cloud at the time the article was published. 
\par
E3 paper \cite{234944} employed Cavium LiquidIO \smartnics, which is equipped with MIPS architecture CPUs, to offload a few microservice-based applications. The goal, as same as other works, is to reduce the latency and power consumption. In a nutshell, the tool, by knowing the system's topology and eliminating extra overhead, distributes the load among the resources in heterogeneous systems with various architectures, x86, and ARM. The idea is to run microservices on \smartnics as long as enough traffic is passed to the hosts.
\par
Many IoT wireless devices have ultra-limited resources; nevertheless, many deep learning applications hoping to be run on the edge need huge resources; take wireless cameras as an example that captures photos to be processed. Moreover, the network's bandwidth may fluctuate for the devices. CLIO paper \cite{10.1145/3372224.3419215} introduces a prototype for those kinds of tools. Previous papers had tried to either reduce the raw data or compress the models; the accuracy dropped, consequently. Considering a deep learning model, CLIO splits the model, and a part of the model with a few layers is offloaded into devices. Further, different slices, with different sizes, from the last layer have been created. The prototype decides to transmit the best choice based on the available bandwidth. Hence the bandwidth is used efficiently; simultaneously, reasonable accuracy is achieved. Keep in mind that the outputs of middle layers have much less data compared to raw data. 
